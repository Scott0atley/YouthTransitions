# Statistical modelling of key variables in social survey data analysis
#### (2016) - Roxanne Connelly, Vernon Gayle, Paul S. Lambert
**Journal**: Methodological Innovations
**Link**:: http://journals.sagepub.com/doi/10.1177/2059799116638002
**DOI**:: 10.1177/2059799116638002
**Links**:: 
**Tags**:: #paper #Methods 
**Cite Key**:: [@connellyStatisticalModellingKey2016]

### Abstract

```
The application of statistical modelling techniques has become a cornerstone of analyses of large-scale social survey data. Bringing this special section on key variables to a close, this final article discusses several important issues relating to the inclusion of key variables in statistical modelling analyses. We outline two, often neglected, issues that are relevant to a great many applications of statistical models based upon social survey data. The first is known as the reference category problem and is related to the interpretation of categorical explanatory variables. The second is the interpretation and comparison of the effects from models for non-linear outcomes. We then briefly discuss other common complexities in using statistical models for social science research; these include the non-linear transformation of variables, and considerations of intersectionality and interaction effects. We conclude by emphasising the importance of two, often overlooked, elements of the social survey data analysis process, sensitivity analysis and documentation for replication. We argue that more attention should routinely be devoted to these issues.
```

### Notes

“The first is known as the reference category problem and is related to the interpretation of categorical explanatory variables. The second is the interpretation and comparison of the effects from models for non-linear outcomes.” (Connelly et al., 2016, p. 1)

“In standard statistical models, the effects of a categorical explanatory variable are assessed by selecting one category as a benchmark against which all other categories are compared. This benchmark category is usually referred to as the ‘reference’ or ‘base’ category. The reference category coefficient is arbitrarily fixed to zero in the model estimation procedure, and the coefficients of the other categories are interpreted as the additional impact of a survey respondent not being in the reference category.” (Connelly et al., 2016, p. 2)

“In theory, the reference category problem can be addressed by presenting results that compare other pairs of categories. It is formally possible to test the difference between the coefficients for any two levels of a categorical explanatory variable by undertaking a t test” (Connelly et al., 2016, p. 2)

“Without access to the variance–covariance matrix, it is not possible for anyone other than the researcher estimating the model to compare a pair of categories which do not include the reference category.” (Connelly et al., 2016, p. 2)

“Gayle and Lambert (2007) offer an accessible introduction to the quasi-variance approach for social science researchers, and they provide a number of Stata and SPSS syntax files and an Excel calculator6 to help secondary data analysts produce and present quasi-standard errors in their work.” (Connelly et al., 2016, p. 3)

“The use of odds ratios is frequently advocated (see Rubin, 2012; Tolmie et al., 2011). Odds ratios are calculated by exponentiating estimates of log odds for the explanatory variables.” (Connelly et al., 2016, p. 5)

“some caution should be applied when using odds ratios to communicate the effects of explanatory variables in logistic regression models” (Connelly et al., 2016, p. 5)

“he use of marginal effects to interpret statistical models is well known in economics (see Greene, 2008), but less known in other social science disciplines. Expressed simply, marginal effects are statistics that are presented to aid the interpretation of modelling results.” (Connelly et al., 2016, p. 5)

“Although not widely used, another useful alternative way to represent the results of logistic regression models is sample enumeration (see Davies, 1992; Gayle et al., 2002). This method operates in a similar fashion to marginal and predicted probabilities but is essentially derived from within the sample rather than using means or specific values to illustrate the effects of other explanatory variables in the model.” (Connelly et al., 2016, p. 6)

“The use of measures such as odds ratios does not immediately address the issue of how much of the observed relationship is explained by one variable in the model (e.g. father’s NS-SEC) compared to how much is explained by the other explanatory variables in the model.” (Connelly et al., 2016, p. 7)

“Through sample enumeration, we hypothetically move all of the children in the least advantaged NS-SEC category to the most advantaged category. Using the logistic regression model results, we can then estimate the proportion of these children who would have achieved an above average test score given their other characteristics” (Connelly et al., 2016, p. 7)

“A detailed example of the sample enumeration process is given in Gayle et al. (2002)” (Connelly et al., 2016, p. 7)

“Log odds (i.e. coefficients) should be presented as this information conveys both the direction and the size of the effect. Conventional standard errors should be reported as” (Connelly et al., 2016, p. 7)

“they indicate the precision of the effect.” (Connelly et al., 2016, p. 8)

“Some researchers might be uncomfortable with the suggestion that p values are not required and as a compromise they might choose to also include asterisks (*) to indicate levels of significance. We strongly advocate reporting quasi-variance based standard errors because these measures facilitate the calculation of comparison intervals and therefore address the reference category problem.” (Connelly et al., 2016, p. 8)

“We also consider that conditional marginal effects (probabilities) should routinely be reported as this greatly aids the interpretation of the effects of explanatory variables. We consider that there is additional benefit in reporting the lower and upper bounds of this measure.” (Connelly et al., 2016, p. 8)

“In addition to these statistical measures, it is always good practice for data analysts to report sample sizes (n) and model fit statistics” (Connelly et al., 2016, p. 8)

“At the current time, we suggest that researchers should report a few alternative measures in published research but provide as many pseudo R2 measures as practicable in the documentation of their workflow.” (Connelly et al., 2016, p. 8)

“nested models, there is a compelling case for using a measure that accounts for parsimony such as the Bayesian Information Criterion (BIC)20 which was proposed by Raftery (1986).” (Connelly et al., 2016, p. 8)

“Table 5. An example of the ideal presentation of a logit model.” (Connelly et al., 2016, p. 8)

“Treiman (2009) states that researchers should always carry out analyses using statistical code (i.e. syntax), and keep a log of the manipulations which are performed on their data.” (Connelly et al., 2016, p. 13)

“More generally, social survey analysts should maintain a consistent workflow in their data analysis (see Long, 2009).” (Connelly et al., 2016, p. 13)